{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# format sig figs\n",
    "pd.set_option('display.float_format', lambda x: '%.5f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = r'J:\\Projects\\FasTrips\\obs\\output\\OBS_fasttrips_demand_v1.1_stochastic_iter1_nocap_30000'\n",
    "\n",
    "# obs_links_dir = r'R:\\FastTrips\\FT Repo\\All input & output files\\OBS_FToutput.csv'\n",
    "obs_links_dir = r'..\\data\\obs\\obs_links.csv'\n",
    "\n",
    "# Probability threshold for observed paths (are observed paths assigned above/below this value by fast-trips)\n",
    "threshold = 0.3\n",
    "\n",
    "# Compare observed path to pathset based on modes, agency, or route\n",
    "# comparison_field = 'path_modes'\n",
    "comparison_field = 'path_agencies'\n",
    "# comparison_field = 'path_routes'\n",
    "\n",
    "non_transit_modes = ['transfer','walk_access','walk_egress','bike_access','bike_egress',\n",
    "                     'PNR_access','PNR_egress','KNR_access','KNR_egress']\n",
    "transit_mode_list = ['local_bus','commuter_rail','express_bus','ferry','heavy_rail','light_rail','premium_bus']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_df(data, unique_fields, record_type=None):\n",
    "    '''Load text data as df, create unique trip record ID, and tag as model/observed record'''\n",
    "    df = pd.read_csv(data)\n",
    "    if record_type != None:\n",
    "        df['record_type'] = record_type    # tag as model/observed record\n",
    "\n",
    "    # Convert all specified unique_fields to string and concatenate as new unique_id field \n",
    "#     df[unique_fields] = pd.DataFrame([df[col].astype('int').astype('str') for col in unique_fields]).T\n",
    "#     df['unique_id'] = df[unique_fields].apply(lambda x: '_'.join(x), axis=1)\n",
    "    df['unique_id'] = df['person_id']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def append(*args):\n",
    "    '''Union dataframes with similar structures'''\n",
    "    df = pd.DataFrame()\n",
    "    for data in args:\n",
    "        df = df.append(data)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def select_common_records(df1,df2,field):\n",
    "    '''Return dataframe of matching, common records only.\n",
    "       Example, person 1034 exists in df1, but not in df2, so new copy of df1 without 1034 is created\n",
    "    '''\n",
    "    df1 = df1[df1[field].isin(df2[field])]\n",
    "    df2 = df2[df2[field].isin(df1[field])]\n",
    "\n",
    "    return df1, df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_transit_agency(df, routes):\n",
    "\n",
    "    df = pd.merge(left=df,right=routes[['route_id','agency_id']],on='route_id',how='left')\n",
    "\n",
    "    df['agency'] = df['agency_id']\n",
    "    df.drop('agency_id',axis=1)\n",
    "    df.fillna(\"\",inplace=True)\n",
    "    df.reset_index(inplace=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def produce_path_fields(df, group):\n",
    "    '''\n",
    "    Concatenate set of fields for pathset_links, e.g. ('bart caltrain') for 2-leg transit trip\n",
    "    Produce concatenated fields for routes, modes, agencies, all components (stops, modes, & routes)\n",
    "    '''\n",
    "    # create \"path_routes\"\n",
    "\n",
    "    for field in ['route_id','mode','agency','A_id','B_id']:\n",
    "        df[field] = df[field].astype('str')\n",
    "        df[field] = df[field].fillna(\"\")\n",
    "        df[field] = df[field].replace('nan',\"\")\n",
    "\n",
    "    df['path_routes'] = df['route_id'].apply(lambda x: x.strip())\n",
    "    path_routes = pd.DataFrame(df.groupby(group)['path_routes'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "    \n",
    "    result_df = pd.DataFrame(index=path_routes.index)\n",
    "    result_df['path_routes'] = path_routes\n",
    "    \n",
    "    # create \"path_modes\"\n",
    "    df['path_modes'] = df['mode'].apply(lambda x: x.strip())\n",
    "    result_df['path_modes'] = pd.DataFrame(df.groupby(group)['mode'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "    \n",
    "    # create \"path_agencies\"\n",
    "    df['path_agencies'] = df['agency'].apply(lambda x: x.strip())\n",
    "    result_df['path_agencies'] = pd.DataFrame(df.groupby(group)['agency'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "\n",
    "    # Create \"path_components\"\n",
    "    df['path_components'] = df['A_id']+\" \"+df['mode']+\" \"+df['route_id'] +\"_\"+ df['B_id']\n",
    "    df['path_components'] = df['path_components'].apply(lambda x: x.strip())\n",
    "    result_df['path_components'] = pd.DataFrame(df.groupby(group)['path_components'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "    \n",
    "    # stop components\n",
    "    df['A_id'] = df['A_id'].astype('str')\n",
    "    df['B_id'] = df['B_id'].astype('str')\n",
    "    df['path_stops'] = df['A_id'] +\" \"+df['B_id']\n",
    "    df['path_stops'] = df['path_stops'].apply(lambda x: x.strip())\n",
    "    result_df['path_stops'] = pd.DataFrame(df.groupby(group)['path_stops'].apply(lambda x: \"%s\" % ' '.join(x).strip()))\n",
    "    # drop repeated records (A_id and B_id overlap as origin and destination nodes for subsequent trips)\n",
    "    result_df['path_stops'] = result_df['path_stops'].apply(lambda row: np.unique(row.split(' ')))\n",
    "    # write out as space separated field\n",
    "    result_df['path_stops'] = result_df['path_stops'].apply(lambda x: \"%s\" % ' '.join(x).strip())\n",
    "    \n",
    "    # Return ID field from index\n",
    "    result_df['unique_id'] = result_df.index.get_level_values(0).values\n",
    "\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- observed data (on-board survey [OBS])\n",
    "- route and agency lookups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "routes = pd.read_csv(r'../data/gtfs/agency_route_1.9.csv')\n",
    "\n",
    "# Load observed and chosenpath_links; add new field designating 'model' or 'observed'\n",
    "obs = load_df(data=obs_links_dir, unique_fields=['person_id','trip_list_id_num'], record_type='observed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Fill floats with integers where available, specifically for stop IDs\n",
    "obs['A_id'] = obs['A_id'].fillna(0).astype('int')\n",
    "obs['B_id'] = obs['B_id'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- chosenpaths links output from Fast-Trips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenpath_links = load_df(data=OUTPUT_DIR + r'\\chosenpaths_links.csv', \n",
    "    unique_fields=['person_id','trip_list_id_num'], record_type='model', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# For some reason there are a lot of duplicates\n",
    "# let's drop them for now\n",
    "chosenpath_links = chosenpath_links.drop_duplicates()\n",
    "\n",
    "# Get the last iteration only\n",
    "chosenpath_links = chosenpath_links[chosenpath_links['iteration'] == chosenpath_links['iteration'].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add transit agency field to chosenpath_links and pathset_links, based on route_id\n",
    "chosenpath_links = add_transit_agency(df=chosenpath_links, routes=routes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenpath_links['A_id'] = chosenpath_links['A_id'].fillna(0).astype('int')\n",
    "chosenpath_links['B_id'] = chosenpath_links['B_id'].fillna(0).astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "observed_path = produce_path_fields(obs, group=['unique_id'])\n",
    "modeled_path = produce_path_fields(chosenpath_links, group=['unique_id'])\n",
    "\n",
    "# Make sure we only evaluate the overlapping unique_id records\n",
    "observed_path = observed_path[observed_path['unique_id'].isin(modeled_path['unique_id'].values)]\n",
    "modeled_path = modeled_path[modeled_path['unique_id'].isin(observed_path['unique_id'].values)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pathset_paths = pd.read_csv(OUTPUT_DIR+ r'/pathset_paths.csv')\n",
    "pathset_paths['unique_id'] = pathset_paths['person_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build comparison fields for pathset_links\n",
    "- from the description column in pathset_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def mode_list(row):\n",
    "\n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    mode_results = []\n",
    "    \n",
    "    for field in row_array:\n",
    "        if field in transit_mode_list + ['transfer','walk_access','walk_egress']:\n",
    "            mode_results.append(field)\n",
    "\n",
    "    # convert from list into space-seperated string\n",
    "    mode_results = ' '.join(mode_results).strip()\n",
    "\n",
    "    return mode_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def route_list(row):\n",
    "    \"\"\"\n",
    "    if route_only=True, return only the route id from the trip id prepended with route info\n",
    "    otherwise return full route_id_xyz, where xyz is the trip id\n",
    "    \"\"\"\n",
    "    \n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    route_results = []\n",
    "    \n",
    "    for i in xrange(len(row_array)):\n",
    "        if row_array[i] in transit_mode_list:\n",
    "            route_results.append(\"_\".join(row_array[i+1].split('_')[:-1]))     # Drop last component of field (trip ID)\n",
    "#                 route_results.append(row_array[i+1])\n",
    "            \n",
    "    route_results =  ' '.join(route_results).strip()\n",
    "    \n",
    "    return route_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stop_list(row):\n",
    "    \n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    # Get the list of transit\n",
    "    trip_with_route_list = []\n",
    "    stop_results = []\n",
    "    \n",
    "    for i in xrange(len(row_array)):\n",
    "        if row_array[i] in transit_mode_list:\n",
    "            # Save this as a field we don't want to include as a stop\n",
    "            trip_with_route_list.append(row_array[i+1])\n",
    "        if row_array[i] not in trip_with_route_list+transit_mode_list+['transfer','walk_access','walk_egress']:\n",
    "            stop_results.append(row_array[i])\n",
    "    \n",
    "    stop_results = ' '.join(stop_results).strip()\n",
    "    \n",
    "    return stop_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def agency_list(row):\n",
    "    \n",
    "    agency_results = []\n",
    "    \n",
    "    # Get list of agencies associated with each transit route\n",
    "    row_array = row.split(' ')\n",
    "    \n",
    "    for route_id in row_array:\n",
    "        agency_results.append(routes[routes['route_id'] == route_id]['agency_id'].values[0])\n",
    "    \n",
    "    agency_results = ' '.join(agency_results).strip()\n",
    "    \n",
    "    return agency_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Mode paths\n",
    "pathset_paths['path_modes'] = pathset_paths['description'].apply(lambda row: mode_list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Route paths\n",
    "pathset_paths['path_routes'] = pathset_paths['description'].apply(lambda row: route_list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Stops\n",
    "pathset_paths['path_stops'] = pathset_paths['description'].apply(lambda row: stop_list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Agencies\n",
    "pathset_paths['path_agencies'] = pathset_paths['path_routes'].apply(lambda row: agency_list(row))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create a stacked csv of observed trip links & model chosenpath_links; export for Tableau\n",
    "chosenpath_links, obs = select_common_records(chosenpath_links, obs,'person_id')\n",
    "chosenpaths_links_with_observed = append(chosenpath_links, obs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add fields for Tableau visualization\n",
    "- transfer from/to agency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86912"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # add additional info about the transfer from and to route/agency for tableau maps\n",
    "chosenpaths_links_with_observed['transfer_from_agency'] = chosenpaths_links_with_observed['agency'].shift(1)\n",
    "chosenpaths_links_with_observed['transfer_to_agency'] = chosenpaths_links_with_observed['agency'].shift(-1)\n",
    "\n",
    "chosenpaths_links_with_observed['transfer_from_route'] = chosenpaths_links_with_observed['route_id'].shift(1)\n",
    "chosenpaths_links_with_observed['transfer_to_route'] = chosenpaths_links_with_observed['route_id'].shift(-1)\n",
    "\n",
    "len(chosenpaths_links_with_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Fill empty strings with 0 for origin and destination fields\n",
    "chosenpaths_links_with_observed[['A_id','B_id']] = chosenpaths_links_with_observed[['A_id','B_id']].replace('',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_id</th>\n",
       "      <th>B_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>  1249</td>\n",
       "      <td> 14663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td> 14663</td>\n",
       "      <td> 14673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td> 14673</td>\n",
       "      <td>  1356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>  1258</td>\n",
       "      <td>  7414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>  7414</td>\n",
       "      <td>  6886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    A_id   B_id\n",
       "0   1249  14663\n",
       "1  14663  14673\n",
       "2  14673   1356\n",
       "3   1258   7414\n",
       "4   7414   6886"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosenpaths_links_with_observed[['A_id','B_id']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- add lat/long values for stops and TAZ origins/destinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Add geography\n",
    "# Get distance from TAZ to stop\n",
    "walk_access_ft = pd.read_csv(r'R:\\FastTrips\\network_draft1.9\\walk_access_ft.txt')[['taz','stop_id','dist']]\n",
    "\n",
    "chosenpaths_links_with_observed[['A_id','B_id']] = chosenpaths_links_with_observed[['A_id','B_id']].astype('float')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Join TAZ-centroid to stop ID distance, first for access trips (A_id as centroid, B_id as transit stop)\n",
    "chosenpaths_links_with_observed = pd.merge(chosenpaths_links_with_observed, walk_access_ft, \n",
    "                                           left_on=['A_id','B_id'],right_on=['taz','stop_id'],how='left')\n",
    "\n",
    "\n",
    "chosenpaths_links_with_observed['walk_access_dist'] = chosenpaths_links_with_observed['dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now join for distance from stop to TAZ centroid (egress)\n",
    "\n",
    "# Drop existing fields from walk_access_ft for clarity\n",
    "chosenpaths_links_with_observed.drop(['taz','stop_id','dist'],axis=1,inplace=True)\n",
    "# for egress trips, A_id is stop ID and B_id is centroid, so reverse the merge fields for walk_access_ft\n",
    "chosenpaths_links_with_observed = pd.merge(chosenpaths_links_with_observed, walk_access_ft, \n",
    "                                           left_on=['A_id','B_id'],right_on=['stop_id','taz'],how='left')\n",
    "chosenpaths_links_with_observed['walk_egress_dist'] = chosenpaths_links_with_observed['dist']\n",
    "chosenpaths_links_with_observed.drop(['taz','stop_id','dist'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "86912"
      ]
     },
     "execution_count": 267,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chosenpaths_links_with_observed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add lat-long where it's missing for stops, using GTFS-based network data\n",
    "# This will give lat long values associated with each A_id location\n",
    "stops = pd.read_csv(r'R:\\FastTrips\\network_draft1.9\\stops.txt')\n",
    "\n",
    "# Join stop lat/lon for A_id stops\n",
    "chosenpaths_links_with_observed = pd.merge(chosenpaths_links_with_observed,stops,left_on='A_id',right_on='stop_id',how='left')\n",
    "chosenpaths_links_with_observed.rename(columns={'stop_lat':'A_lat', 'stop_lon':'A_lon'},inplace=True)\n",
    "\n",
    "chosenpaths_links_with_observed = pd.merge(chosenpaths_links_with_observed,stops,left_on='B_id',right_on='stop_id',how='left')\n",
    "chosenpaths_links_with_observed.rename(columns={'stop_lat':'B_lat','stop_lon':'B_lon'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now all stops should have lat/long\n",
    "# Next add lat and lon for TAZ fields\n",
    "\n",
    "# Centroid locations for each TAZ\n",
    "taz = pd.read_csv(r'R:\\FastTrips\\network_draft1.9\\taz_coords.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# For the origin TAZs\n",
    "chosenpaths_links_with_observed = pd.merge(chosenpaths_links_with_observed,taz,left_on='A_id',right_on='taz',how='left')\n",
    "chosenpaths_links_with_observed.rename(columns={'lat':'A_taz_lat','lon':'A_taz_lon'},inplace=True)\n",
    "\n",
    "# For destination TAZs\n",
    "chosenpaths_links_with_observed = pd.merge(chosenpaths_links_with_observed,taz,left_on='B_id',right_on='taz',how='left')\n",
    "chosenpaths_links_with_observed.rename(columns={'lat':'B_taz_lat','lon':'B_taz_lon'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# chosenpaths_links_with_observed[['A_id','B_id','A_lat','A_lon','B_lat','B_lon','A_taz_lat','A_taz_lon','B_taz_lat','B_taz_lon']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Fill the missing lat and lon fields with taz_lat and taz_lon\n",
    "chosenpaths_links_with_observed['A_lat'].fillna(chosenpaths_links_with_observed['A_taz_lat'],inplace=True)\n",
    "chosenpaths_links_with_observed['A_lon'].fillna(chosenpaths_links_with_observed['A_taz_lon'],inplace=True)\n",
    "\n",
    "chosenpaths_links_with_observed['B_lat'].fillna(chosenpaths_links_with_observed['B_taz_lat'],inplace=True)\n",
    "chosenpaths_links_with_observed['B_lon'].fillna(chosenpaths_links_with_observed['B_taz_lon'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenpaths_links_with_observed['stop_lat'].fillna(chosenpaths_links_with_observed['lat'],inplace=True)\n",
    "chosenpaths_links_with_observed['stop_lon'].fillna(chosenpaths_links_with_observed['lon'],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A_id</th>\n",
       "      <th>B_id</th>\n",
       "      <th>A_lat</th>\n",
       "      <th>A_lon</th>\n",
       "      <th>B_lat</th>\n",
       "      <th>B_lon</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td> 1249.00000</td>\n",
       "      <td>14663.00000</td>\n",
       "      <td>37.58460</td>\n",
       "      <td>-122.34119</td>\n",
       "      <td>37.58103</td>\n",
       "      <td>-122.34706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14663.00000</td>\n",
       "      <td>14673.00000</td>\n",
       "      <td>37.58103</td>\n",
       "      <td>-122.34706</td>\n",
       "      <td>37.44364</td>\n",
       "      <td>-122.16520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14673.00000</td>\n",
       "      <td> 1356.00000</td>\n",
       "      <td>37.44364</td>\n",
       "      <td>-122.16520</td>\n",
       "      <td>37.44673</td>\n",
       "      <td>-122.15701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 1258.00000</td>\n",
       "      <td> 7414.00000</td>\n",
       "      <td>37.57336</td>\n",
       "      <td>-122.33748</td>\n",
       "      <td>37.56974</td>\n",
       "      <td>-122.33609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 7414.00000</td>\n",
       "      <td> 6886.00000</td>\n",
       "      <td>37.56974</td>\n",
       "      <td>-122.33609</td>\n",
       "      <td>37.44334</td>\n",
       "      <td>-122.16432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         A_id        B_id    A_lat      A_lon    B_lat      B_lon\n",
       "0  1249.00000 14663.00000 37.58460 -122.34119 37.58103 -122.34706\n",
       "1 14663.00000 14673.00000 37.58103 -122.34706 37.44364 -122.16520\n",
       "2 14673.00000  1356.00000 37.44364 -122.16520 37.44673 -122.15701\n",
       "3  1258.00000  7414.00000 37.57336 -122.33748 37.56974 -122.33609\n",
       "4  7414.00000  6886.00000 37.56974 -122.33609 37.44334 -122.16432"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosenpaths_links_with_observed[['A_id','B_id','A_lat','A_lon','B_lat','B_lon']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "chosenpaths_links_with_observed.to_csv(OUTPUT_DIR + '/' + 'chosenpaths_links_with_observed.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Modeled v Observed\n",
    "### Produce new output file path_comparison.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Combine the observed and modeled path files\n",
    "df = pd.merge(observed_path, modeled_path, on='unique_id',suffixes=(\"_observed\",\"_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- compare routes, modes, and agencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Build list of routes used in observed and modeled trips\n",
    "df['model_path_route_list'] = df['path_routes_model'].apply(lambda x: x.split(\" \"))\n",
    "df['obs_path_route_list'] = df['path_routes_observed'].apply(lambda x: x.split(\" \"))\n",
    "\n",
    "# Build list of modes used in observed and modeled trips\n",
    "df['model_path_mode_list'] = df['path_modes_model'].apply(lambda x: x.split(\" \"))\n",
    "df['obs_path_mode_list'] = df['path_modes_observed'].apply(lambda x: x.split(\" \"))\n",
    "\n",
    "# Build list of transit agencies used in observed and modeled trips\n",
    "df['model_path_agencies_list'] = df['path_agencies_model'].apply(lambda x: x.split(\" \"))\n",
    "df['obs_path_agencies_list'] = df['path_agencies_observed'].apply(lambda x: x.split(\" \"))\n",
    "\n",
    "# Build list of stops used in observed and modeled trips\n",
    "df['model_path_stops_list'] = df['path_stops_model'].apply(lambda x: x.split(\" \"))\n",
    "df['obs_path_stops_list'] = df['path_stops_observed'].apply(lambda x: x.split(\" \"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>person_id</th>\n",
       "      <th>trip_list_id_num</th>\n",
       "      <th>linkmode</th>\n",
       "      <th>A_id</th>\n",
       "      <th>B_id</th>\n",
       "      <th>linknum</th>\n",
       "      <th>mode</th>\n",
       "      <th>route_id</th>\n",
       "      <th>agency</th>\n",
       "      <th>record_type</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>path_routes</th>\n",
       "      <th>path_modes</th>\n",
       "      <th>path_agencies</th>\n",
       "      <th>path_components</th>\n",
       "      <th>path_stops</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td> 2</td>\n",
       "      <td>  access</td>\n",
       "      <td>  1249</td>\n",
       "      <td> 14661</td>\n",
       "      <td> 0</td>\n",
       "      <td>    KNR_access</td>\n",
       "      <td>                            </td>\n",
       "      <td>         </td>\n",
       "      <td> observed</td>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td>                            </td>\n",
       "      <td>    KNR_access</td>\n",
       "      <td>         </td>\n",
       "      <td>                            1249 KNR_access _14661</td>\n",
       "      <td>  1249 14661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td> 2</td>\n",
       "      <td> transit</td>\n",
       "      <td> 14661</td>\n",
       "      <td> 14673</td>\n",
       "      <td> 1</td>\n",
       "      <td> commuter_rail</td>\n",
       "      <td> Caltrain_Millbrae Palo Alto</td>\n",
       "      <td> caltrain</td>\n",
       "      <td> observed</td>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td> Caltrain_Millbrae Palo Alto</td>\n",
       "      <td> commuter_rail</td>\n",
       "      <td> caltrain</td>\n",
       "      <td> 14661 commuter_rail Caltrain_Millbrae Palo Alt...</td>\n",
       "      <td> 14661 14673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td> 2</td>\n",
       "      <td>  egress</td>\n",
       "      <td> 14673</td>\n",
       "      <td>  1356</td>\n",
       "      <td> 2</td>\n",
       "      <td>   walk_egress</td>\n",
       "      <td>                            </td>\n",
       "      <td>         </td>\n",
       "      <td> observed</td>\n",
       "      <td> 10---Caltrain---2014</td>\n",
       "      <td>                            </td>\n",
       "      <td>   walk_egress</td>\n",
       "      <td>         </td>\n",
       "      <td>                           14673 walk_egress _1356</td>\n",
       "      <td>  14673 1356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              person_id  trip_list_id_num linkmode   A_id   B_id  linknum  \\\n",
       "3  10---Caltrain---2014                 2   access   1249  14661        0   \n",
       "4  10---Caltrain---2014                 2  transit  14661  14673        1   \n",
       "5  10---Caltrain---2014                 2   egress  14673   1356        2   \n",
       "\n",
       "            mode                     route_id    agency record_type  \\\n",
       "3     KNR_access                                           observed   \n",
       "4  commuter_rail  Caltrain_Millbrae Palo Alto  caltrain    observed   \n",
       "5    walk_egress                                           observed   \n",
       "\n",
       "              unique_id                  path_routes     path_modes  \\\n",
       "3  10---Caltrain---2014                                  KNR_access   \n",
       "4  10---Caltrain---2014  Caltrain_Millbrae Palo Alto  commuter_rail   \n",
       "5  10---Caltrain---2014                                 walk_egress   \n",
       "\n",
       "  path_agencies                                    path_components  \\\n",
       "3                                           1249 KNR_access _14661   \n",
       "4      caltrain  14661 commuter_rail Caltrain_Millbrae Palo Alt...   \n",
       "5                                          14673 walk_egress _1356   \n",
       "\n",
       "    path_stops  \n",
       "3   1249 14661  \n",
       "4  14661 14673  \n",
       "5   14673 1356  "
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs[obs['unique_id'] == '10---Caltrain---2014']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'index', u'person_id', u'person_trip_id', u'pathnum', u'linkmode', u'A_seq', u'B_seq', u'linknum', u'A_id', u'B_id', u'trip_id', u'route_id', u'mode', u'chosen', u'new_A_time', u'new_B_time', u'new_linktime min', u'new_waittime min', u'missed_xfer', u'distance', u'sim_cost', u'board_time', u'overcap', u'alight_time', u'iteration', u'record_type', u'unique_id', u'agency_id', u'agency', u'path_routes', u'path_modes', u'path_agencies', u'path_components', u'path_stops'], dtype='object')"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosenpath_links[chosenpath_links['unique_id'] == '10---Caltrain---2014'].columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>person_id</th>\n",
       "      <th>person_trip_id</th>\n",
       "      <th>pathnum</th>\n",
       "      <th>linkmode</th>\n",
       "      <th>A_seq</th>\n",
       "      <th>B_seq</th>\n",
       "      <th>linknum</th>\n",
       "      <th>A_id</th>\n",
       "      <th>B_id</th>\n",
       "      <th>...</th>\n",
       "      <th>alight_time</th>\n",
       "      <th>iteration</th>\n",
       "      <th>unique_id</th>\n",
       "      <th>agency_id</th>\n",
       "      <th>agency</th>\n",
       "      <th>path_routes</th>\n",
       "      <th>path_modes</th>\n",
       "      <th>path_agencies</th>\n",
       "      <th>path_components</th>\n",
       "      <th>path_stops</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>record_type</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>model</th>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td>...</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "      <td> 3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index  person_id  person_trip_id  pathnum  linkmode  A_seq  \\\n",
       "record_type                                                               \n",
       "model            3          3               3        3         3      3   \n",
       "\n",
       "             B_seq  linknum  A_id  B_id     ...      alight_time  iteration  \\\n",
       "record_type                                 ...                               \n",
       "model            3        3     3     3     ...                3          3   \n",
       "\n",
       "             unique_id  agency_id  agency  path_routes  path_modes  \\\n",
       "record_type                                                          \n",
       "model                3          3       3            3           3   \n",
       "\n",
       "             path_agencies  path_components  path_stops  \n",
       "record_type                                              \n",
       "model                    3                3           3  \n",
       "\n",
       "[1 rows x 33 columns]"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosenpath_links[chosenpath_links['unique_id'] == '10---Caltrain---2014'].groupby('record_type').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " # Isolate transit modes only, because all trips should have walk & transfer components\n",
    "    \n",
    "df['model_transit_modes'] = df['model_path_mode_list'].apply(\n",
    "    lambda row: [element for element in row if element not in non_transit_modes])\n",
    "df['obs_transit_modes'] = df['obs_path_mode_list'].apply(\n",
    "    lambda row: [element for element in row if element not in non_transit_modes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div style=\"max-height:1000px;max-width:1500px;overflow:auto;\">\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>obs_transit_modes</th>\n",
       "      <th>model_transit_modes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>            [commuter_rail]</td>\n",
       "      <td>        [commuter_rail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>            [commuter_rail]</td>\n",
       "      <td> [local_bus, local_bus]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>               [heavy_rail]</td>\n",
       "      <td>           [heavy_rail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td> [local_bus, commuter_rail]</td>\n",
       "      <td>        [commuter_rail]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>               [heavy_rail]</td>\n",
       "      <td>            [local_bus]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            obs_transit_modes     model_transit_modes\n",
       "0             [commuter_rail]         [commuter_rail]\n",
       "1             [commuter_rail]  [local_bus, local_bus]\n",
       "2                [heavy_rail]            [heavy_rail]\n",
       "3  [local_bus, commuter_rail]         [commuter_rail]\n",
       "4                [heavy_rail]             [local_bus]"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[['obs_transit_modes','model_transit_modes']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Find the intersection between the chosen model/observed paths using different criteria\n",
    "# Which are in common between model and observed?\n",
    "\n",
    "# transit route IDs only\n",
    "df.apply(lambda row: all(i in row['model_path_route_list'] for i in row['obs_path_route_list']), axis=1)\n",
    "df['routes_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_route_list'], df['obs_path_route_list'])]\n",
    "\n",
    "# stops only\n",
    "df.apply(lambda row: all(i in row['model_path_stops_list'] for i in row['obs_path_stops_list']), axis=1)\n",
    "df['stops_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_stops_list'], df['obs_path_stops_list'])]\n",
    "\n",
    "# All Modes (including transfer, access/egress)\n",
    "df.apply(lambda row: all(i in row['model_path_mode_list'] for i in row['obs_path_mode_list']), axis=1)\n",
    "df['all_modes_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_mode_list'], df['obs_path_mode_list'])]\n",
    "\n",
    "# Transit modes only (type of vehicle taken and number of boardings)\n",
    "df.apply(lambda row: all(i in row['model_path_mode_list'] for i in row['obs_path_mode_list']), axis=1)\n",
    "df['transit_modes_intersection'] = [list(set(a).intersection(set(b))) for a, b in zip(df['model_transit_modes'], df['obs_transit_modes'])]\n",
    "\n",
    "# Agency Intersection\n",
    "df.apply(lambda row: all(i in row['model_path_agencies_list'] for i in row['obs_path_agencies_list']), axis=1)\n",
    "df['agency_intersection'] = \\\n",
    "    [list(set(a).intersection(set(b))) for a, b in zip(df['model_path_agencies_list'], \n",
    "        df['obs_path_agencies_list'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Exact Match of path routes, modes, & components\n",
    "# Isolate rows (trip legs) with matching path routes\n",
    "complete_route_match = df[df['path_routes_observed'] == df['path_routes_model']]\n",
    "complete_mode_match = df[df['path_modes_observed'] == df['path_modes_model']]\n",
    "complete_agency_match = df[df['path_agencies_observed'] == df['path_agencies_model']]\n",
    "complete_stop_match = df[df['path_stops_observed'] == df['path_stops_model']]\n",
    "\n",
    "complete_route_match['complete_route_match'] = 1\n",
    "complete_mode_match['complete_mode_match'] = 1\n",
    "complete_agency_match['complete_agency_match'] = 1\n",
    "complete_stop_match['complete_stop_match'] = 1\n",
    "\n",
    "# Add new columns to the larger dataframe indicating if the row is a complete match\n",
    "df = pd.merge(df, complete_mode_match[['unique_id','complete_mode_match']], how='left', on='unique_id')\n",
    "\n",
    "\n",
    "df = pd.merge(df, complete_route_match[['unique_id','complete_route_match']], how='left', on='unique_id')\n",
    "df = pd.merge(df, complete_agency_match[['unique_id','complete_agency_match']], how='left', on='unique_id')\n",
    "df = pd.merge(df, complete_stop_match[['unique_id','complete_stop_match']], how='left', on='unique_id')\n",
    "\n",
    "for field in ['mode','route','agency', 'stop']:\n",
    "    df['complete_'+field+'_match']=  df['complete_'+field+'_match'].replace('nan',0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now we find the percent of trips with matching routes or partial matching routes\n",
    "\n",
    "# Join the filtered data to the original results\n",
    "df['common_route_count'] = [len(row) for row in df['routes_intersection']]\n",
    "df['common_mode_count'] = [len(row) for row in df['all_modes_intersection']]\n",
    "df['common_transit_mode_count'] = [len(row) for row in df['transit_modes_intersection']]\n",
    "df['common_agency_count'] = [len(row) for row in df['agency_intersection']]\n",
    "df['common_stop_count'] = [len(row) for row in df['stops_intersection']]\n",
    "\n",
    "# How many rows have at least one mode in common?\n",
    "df['partial_mode_match'] = [1 if row > 0 else 0 for row in df['common_mode_count']]\n",
    "df['partial_transit_mode_match'] = [1 if row > 0 else 0 for row in df['common_transit_mode_count']]\n",
    "df['partial_route_match'] = [1 if row > 0 else 0 for row in df['common_route_count']]\n",
    "df['partial_agency_match'] = [1 if row > 0 else 0 for row in df['common_agency_count']]\n",
    "df['partial_stop_match'] = [1 if row > 0 else 0 for row in df['common_stop_count']]\n",
    "\n",
    "# Export\n",
    "df.to_csv(OUTPUT_DIR + r'/path_intersection.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- check if observed path is in pathset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([u'person_id', u'person_trip_id', u'pathdir', u'pathmode', u'pathnum', u'pf_cost', u'pf_probability', u'description', u'chosen', u'missed_xfer', u'sim_cost', u'ln_PS', u'logsum_component', u'logsum', u'probability', u'iteration', u'simulation_iteration', u'path_modes', u'path_routes', u'path_stops', u'path_agencies'], dtype='object')"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pathset_links\n",
    "pathset_paths.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Add a field to the new_pathset that lists the pathnum\n",
    "# pathset_links['pathnum'] = pathset_links.index.get_level_values(1)\n",
    "\n",
    "# Join paths based on comparison_field, as defined in script header\n",
    "# Resulting df is merge of all observed paths that have a corresponding path in the pathset for their unique_id\n",
    "# observed paths with no corresponding path in pathset will have NaN for fields \"_pathset\" suffix\n",
    "newdf = pd.merge(observed_path, pathset_paths, how='left',\n",
    "          left_on=['unique_id',comparison_field],right_on=['unique_id',comparison_field], suffixes=['_obs','_pathset'])\n",
    "\n",
    "# Join this data with the pathset path file to get pf_probability associated with the observed path\n",
    "# newdf = pd.merge(df, pathset_paths[['unique_id','pathnum','pf_probability']], \n",
    "#                  left_on=['unique_id','pathnum'], right_on=['unique_id','pathnum'],\n",
    "#                  how='left')\n",
    "\n",
    "# Fields with NaN marked as no match since no matching path was found in pathset\n",
    "newdf['probability'] = newdf['pf_probability'].fillna('no_match')\n",
    "\n",
    "# Grab the highest and lowest probabilities from pathset paths\n",
    "# want to test that the observed path has a reasonably high probability\n",
    "max_prob = newdf.groupby('unique_id').max()['probability']\n",
    "min_prob = newdf.groupby('unique_id').min()['probability']\n",
    "\n",
    "# Reshape those results and export to dataframe\n",
    "prob_export = pd.DataFrame([max_prob,min_prob]).T\n",
    "prob_export.columns = ['max_prob','min_prob']\n",
    "\n",
    "\n",
    "# Reformat at binary to indicate whether a path was found in the pathset\n",
    "prob_export['path_exists'] = prob_export['max_prob'].apply(lambda row_value: 0 if row_value == 'no_match' else 1)\n",
    "prob_export.to_csv('temp_prob_export.csv')\n",
    "\n",
    "# Create a variabale to indicate if the max probability of the observed path\n",
    "# is over a given threshold, as defined at top of script\n",
    "try:\n",
    "    prob_export.ix[prob_export['max_prob'] >= threshold, 'above_threshold'] = 1\n",
    "    prob_export.ix[prob_export['max_prob'] < threshold, 'above_threshold'] = 0\n",
    "    prob_export.ix[prob_export['max_prob'] == 'no_match', 'above_threshold'] = -1\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# export the results probabilities, path_existence, threshold data,\n",
    "# also add the modeled and observed (chosen) path characteristics\n",
    "prob_export['unique_id'] = prob_export.index\n",
    "\n",
    "tempdf = pd.merge(observed_path,modeled_path,on='unique_id',suffixes=['_obs','_model'],how='left')\n",
    "export_df = pd.merge(prob_export,tempdf,on='unique_id',how='left')\n",
    "\n",
    "export_df['person_id'] = export_df['unique_id'].apply(lambda row: row.split(\"_\")[0])\n",
    "export_df['trip_list_id_num'] = export_df['unique_id'].apply(lambda row: row.split(\"_\")[-1])\n",
    "\n",
    "export_df.to_csv(OUTPUT_DIR + '\\path_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.36050358390001835"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_df['path_exists'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "path_exists       1.00000\n",
       "above_threshold   0.51389\n",
       "dtype: float64"
      ]
     },
     "execution_count": 302,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "export_df[export_df['max_prob'] != 'no_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.009832751332475648"
      ]
     },
     "execution_count": 303,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['complete_route_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2018011394964161"
      ]
     },
     "execution_count": 304,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['complete_stop_match'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3072964528579305"
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['complete_agency_match'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Add time fields\n",
    "- OBS data has no time fields, but we still want to query by time of day so copy FT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
